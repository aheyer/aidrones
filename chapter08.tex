\renewcommand{\deutschertitel}{Stereokameras mit einem Raspberry Pi 5}
\renewcommand{\englischertitel}{Stereo camera setup with a Raspberry Pi 5}
\chapter[\texorpdfstring{\protect{\vspace{2pt}\englischertitel}}{\englischertitel}]{}
\kapitel{\deutschertitel}
\thispagestyle{empty}

\label{KapitelStereoVision}

\begin{paracol}{2}[]

{\raggedright\huge\bfseries\sffamily \englischertitel \par\ } \\[1.8ex]

\switchcolumn

{\raggedright\huge\bfseries\sffamily \deutschertitel \par\ } \\[1.8ex]

\coleng

Test Eng

\colger

Stereokameras sind ein klassisches Werkzeug, um Tiefenerkennung durchzuführen. Der Vorteil gegenüber einem einfachen Kamerasetup, ist das kein Modell trainiert werden muss, um die Tiefenerkennung zu konfigurieren. 

Alles was dafür benötigt wird sind zwei baugleiche Kameras und ein Computer, der die entsprechenden Berechnungen mithilfe von OpenCV durchführt. Alternativ kann auch ein Stereokameramodul verwendet werden, welches explizit für solche Anwendungsfälle gedacht ist. Diese sind meistens platzsparender und einfacher zu montieren/anzuschließen. Allerdings verursachen sie zusätzliche Kosten.

Der folgende Guide basiert auf einem Raspberry Pi 5 mit 8 GB Arbeitsspeicher und zwei Kameramodulen vom Modell: RB-CAMERA-JT-V2-120. Der Grund hierfür ist, dass nur das Raspberry Pi 5 zwei Kameramodule mit paralleler Nutzung ermöglicht. Vorangegangene Modelle würden einen Adapter benötigen, welcher keine parallele Nutzung beider Kameras zulässt.

\colende

\begin{figure}[htb!]
	\centering
	\includegraphics[width=\linewidth]{StereoVision_Contraption.jpg}
	\caption{Stereo Vision Contraption}
	\label{StereoVisionContraption}
\end{figure}

\colstart

Test Eng

\colger

Die Kameras werden nebeneinander montiert, und mit zwei Minikabeln angeschlossen. Die Kameras sollten möglichst parallel montiert werden, da es jedoch nicht möglich ist dies perfekt zu machen wird es später softwareseitig korrigiert.

Ein solches Setup ist jedoch nur für größere Drohnen geeignet, welche große Batterikapazitäten tragen können. Bei kleineren Drohnen würde das Raspberry Pi 5 die Flugzeit sehr stark reduzieren würde. Für kleinere Drohnen, sollte mit einem einfachen Kamerasetup und einem Modell gearbeitet werden.

\colende

\renewcommand{\deutschertitel}{Camera Calibration}
\renewcommand{\englischertitel}{Kamerakalibrierung}
\makroabschnitt
\label{AbschnittStereoVisionKalibrierung}

Test Eng

\colger

Die Notwendigkeit der Kamerakalibrierung ergibt sich aus der Konstruktion (Abbildung~\ref{StereoVisionContraption}), denn die beiden Kameras sind nicht exakt parallel montiert. Es wäre theoretisch möglich diese Konstruktion immer wieder iterativ anzupassen bis dies der Fall ist, jedoch ist es äußerst unwahrscheinlich, dass die Linsen der beiden Kameras exakt gleich sind.

Das ist vor allem relevant für die Raspberry-Pi-Kameras, da es sich hier um sogenannte Pinhole-Kameras handelt. Solche Kameras haben häufig eine recht starke Radialverzerrung. Diese Art von Verzerrung lässt gerade Linien kurvig erscheinen. Eine weitere relevante Art der Verzerrung ist die Tangentialverzerrung. Diese entsteht, wenn die Linse der Kamera nicht komplett parallel zur Oberfläche ist, die sie aufnimmt. Dies ist ebenfalls äußerst schwierig zu bewerkstelligen, besonders mit zwei Kameras.

Das bedeutet also, dass unabhängig von den verwendeten Kameramodulen (inkl. Stereomodulen) eine Kalibrierung notwenig ist. Dabei werden die beiden Kameras zunächst einzeln kalibriert und dann zusammen einer Stereokalibrierung unterzogen.

Bei der Kalibrierung wird versucht diese sogenannten Verzerrungskoeffizienten zu finden.
Diese werden durch $k_1$, $k_2$, $k_3$ für die Radialverzerrung und $p_1$ und $p_2$ für die Tangentialverzerrung.

$$ dist = (k_1, k_2, k_3, p_1, p_2) $$

Darüber hinaus werden intrinsischen und extrinsischen Kameraparameter berechnet. Die intrinsischen Parameter beziehen sich auf die Einstellungen der Kamera. Dabei handelt es sich um die Brennweite $(f_x, f_y)$ und das optische Zentrum $(c_x, c_y)$. Aus diesen beiden Pixelwerten ergibt sich die Kameramatrix.

$$ camMtx = \begin{bmatrix}
	f_x & 0 & c_x \\
	0 & f_y & c_y \\
	0 & 0 & 1
\end{bmatrix}$$

Bei den extrinsischen Parametern handelt es sich um die Rotationsmatrix und den Übersetzungsvektor ($R$ und $t$), welche benötigt werden, um den 3D-Punkt in der physischen Welt auf den 2D-Punkt in der Abbildung zu projizieren. Diese können dann zu einer homogenen Transformation kombiniert werden, welche die Übersetzung des Punktes in der realen Welt ($P_w$) zu einem Punkt im Koordinatensystem der Kamera ($P_c$) beschreibt.

$$ P_c = \begin{bmatrix}
	R & t \\
	0 & 1
\end{bmatrix} P_w$$ 

Mithilfe dieser Parameter ist es möglich ein Bild, was mit einer kalibrierten Kamera aufgenommen wurde zu entzerren. Dies ist ein Zwischenschritt bei der Aufnahmen von Stereobildern. Wichtig ist dabei, dass das Bild mit der gleichen Auflösung aufgenommen werden muss, mit der die Kamera kalibriert wurde. Sollte das Bild skaliert werden, müssen zumindest die intrinsischen Kameraparameter um den selben Faktor skaliert werden. 

Die Kalibrierung erfolgt mithilfe eines Kalibrierungsmusters. Hierbei besteht die Auswahl zwischen einem Schachbrettmuster, einem Raster aus Kreisen und einem sogennanten ChAruco-Board. Letzteres ist ein Schachbrettmuster, welches mit Aruco-Markierungen versehen wurde.

% Bild aller drei Kalibrierungsmuster einfügen.

Der Vorteil dieses ChAruco-Patterns ist, dass die Aruco-Markierungen einzigartig sind und individuell zugeordnet werden können. Dies ermöglicht es Kalibrierungsbilder aufzunehmen, die teilweise bedeckt sind oder auf denen nicht alle Ecken des Schachbretts zu sehen sind. Dies verspricht in der Regel eine höhere Genauigkeit und sollte, wenn möglich einem Schachbrettmuster vorgezogen werden.

Bei den anderen beiden Pattern müssen alle Ecken, bzw. Kreise im Bild zu sehen sein. Dies macht es besonders schwierig die Ecken abzudecken, welche oft kritisch sind für eine gute Genauigkeit. Des weiteren werden dabei mehr Bilder benötigt. Wie viele Bilder konkret benötigt werden, sollte im Einzelfall getestet werden. Zehn sind grundsätzlich ein guter Startpunkt, da diese mindestens für die Kalibrierung mit einem Schachbrettmuster benötigt werden. Die anderen Muster können gegebenenfalls auch mit weniger auskommen. 

Unabhängig vom gewählten Kalibrierungsmuster, sollte die Kalibrierung ungefähr in der Entfernung durchgeführt werden, in der die Kamera später eingesetzt wird. Darüber hinaus sollte das Muster mindestens die Hälfte des Bildes bedecken. Außerdem sollte es auf einer flachen Oberfläche abgebildet werden und hochauflösend sein. Es empfiehlt sich hier einen Bildschirm zu verwenden.

Die Bilder sollten auch aus unterschiedlichen Winkeln und mit unterschiedlichen Neigungen gemacht werden. Auf eine gute Belichtung sollte auch geachtet werden, da ungleichmäßige Belichtung dafür sorgen kann, dass nicht alle Punkte auf jedem Bild erkannt werden. 

Für das Aufnehmen der Bilder in einem Dual-Camera-Setup empfiehlt es sich den Auslöser zu synchronisieren. Im Falle von Python kann dazu \texttt{threading.Barrier()} verwendet werden (siehe Abbildung~\ref{ListingTakingCalibrationPictures}). 

\colende

\begin{figure}
	\begin{lstlisting}[style=shell]
from picamera2 import Picamera2
from time import sleep
import threading
from libcamera import Transform

cam_zero = Picamera2(0)
cam_one = Picamera2(1)
barrier = threading.Barrier(2)

def capture_zero(index):
	barrier.wait()
	cam_zero.capture_file(f"/path/to/images_0/{index}.jpg")

def capture_one(index):
	barrier.wait()
	cam_one.capture_file(f"/path/to/images_1/{index}.jpg")

try:
	while True:
		print(counter)
		pic_zero = threading.Thread(target=capture_zero, args=(counter,))
		pic_one = threading.Thread(target=capture_one, args=(counter,))
		pic_zero.start()
		pic_one.start()
		pic_zero.join()
		pic_one.join()
		counter += 1
		sleep(3)

except KeyboardInterrupt:
	cam_zero.close()
	cam_one.close()
	\end{lstlisting}
	\caption{Test Listing}
	\label{ListingTakingCalibrationPictures}
\end{figure}

\colstart

Test Eng

\colger

Als letzter Schritt vor der Kalibrierung müssen die Bilder der beiden Kameras ausgewertet werden. Dies geschieht mit Hilfe von \texttt{cv2.aruco.CharucoDetector(board)}. Dieser wird verwendet, um die Ecken des Schachbretts und die entsprechnden Aruco-Markierungen zu erkennen und als Zahlenwerte zu beschreiben. Diese Zahlenwerte werden dann als Input für \texttt{cv2.calibrateCamera()} verwendet.

Der Output dieser Funktion sind die intrinsischen und extrinsischen Kameraparameter die Verzerrungskoeffizenten, die Rotationsmatrix und der Übersetzungsvektor, sowie die mittlere quadratische Abweichung zur Evaluation der Kalibrierung. Diese sollte idealerweise kleiner als 1 sein. Das ist jedoch noch keine Garantie für ein gutes Resultat. Sollte die Abweichung kleiner als 1 sein und die Bilder können nicht entzerrt werden, empfiehlt es sich die Abweichung der Bilder einzeln zu prüfen. 

Nicht immer erkennt der Detector alle relevanten Punkte, unabhängig von gutem Licht. Durch das löschen schlechter Bilder kann das Resultat weiter verbessert werden. Zu diesem Zweck können die mit \texttt{detector.detectBoard(image)} entdeckten Marker mit \texttt{cv2.aruco.drawDetectedCornersCharuco()} gezeichnet werden und dann mit \texttt{cv2.imwrite()} ausgegeben werden. 

Durch visuelles inspizieren können Probleme mit den Kalibrierungsbildern einfacher erkannt werden. Dies ist vor Allem interessant für Schachbrettmuster, da nicht garantiert ist, dass die Ecken immer in der gleichen Reihenfolge erkannt werden. 

\colende

\begin{figure}
	\begin{lstlisting}[style=shell]
import cv2
import numpy as np
import os
from glob import glob

def charuco_calibration(images_glob : str, cam : int):
	dictionary = cv2.aruco.getPredefinedDictionary(ARUCO_DICT)
	board = cv2.aruco.CharucoBoard((SQUARES_VERTICALLY, SQUARES_HORIZONTALLY), SQUARE_LENGTH, MARKER_LENGTH, dictionary)
	params = cv2.aruco.DetectorParameters()
	detector = cv2.aruco.CharucoDetector(board)
	image_paths = glob(images_glob)
	all_charuco_corners = []
	all_charuco_ids = []
	all_image_pts = []
	all_object_pts = []
	counter = 1
	
	for image_path in image_paths:
		image = cv2.imread(image_path)
		grayscaled = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
		charuco_corners, charuco_ids, marker_corners, marker_ids = detector.detectBoard(image)
		
		if charuco_corners is not None:   
			image = cv2.aruco.drawDetectedCornersCharuco(image, charuco_corners, charuco_ids)
			object_points, image_points = board.matchImagePoints(charuco_corners, charuco_ids)
			all_object_pts.append(object_points)
			all_image_pts.append(image_points)
			all_charuco_corners.append(charuco_corners)
			all_charuco_ids.append(charuco_ids)

			counter += 1
			
	image_height, image_width = image.shape[:2]

	retval, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(all_object_pts, all_image_pts, (image_height, image_width), None, None)
	return all_object_pts, all_image_pts, retval, camera_matrix, dist_coeffs, rvecs, tvecs, image_height, image_width
	\end{lstlisting}
	\caption{Single Camera calibration}
\end{figure}

\colstart

Test Eng

\colger

% explain cv2.getOptimalCameraMatrix()
% Insert calibration picture with drawn charuco points.

Sollte das Ergebnis der einzelnen Kalibrierung gut genug sein, kann zum Nächsten Schritt übergegangen werden: Der eigentlichen Stereokalibrierung. Dies ist nötig, um die Bilder der beiden Kameras auf eine Linie zu bringen, auch wenn diese leicht unterschiedlich montiert sind. Das bedeutet, dass interessante Punkte in einem Bild die gleiche Y-Koordinate (Pixelwert) haben.

Hierfür wird die Funktion \texttt{cv2.stereoCalibrate} verwendet. Entscheidend ist dabei, dass die Kalibrierungsbilder synchronisiert sind. Dies wird mit dem Code in Abbildung \ref{ListingTakingCalibrationPictures} sichergestellt. Bei Bedarf kann allerdings auch ein zweiter Satz Kalibrierungsbilder angefertigt werden. In diesen müssen dann die Punkte erneut entdeckt werden. 

% Die Imagepoints und die Matrizen der einzelnen Kamers dienen dann als Input
% mit CALIB_FIX_INTRINSIC werden die intrinsischen Matrizen festgesetzt. 


6. Stereo Kalibrierung
7. Undistort Rectify Map 
8. Speichern der Kalibrierungseinstellungen

\colende

\renewcommand{\deutschertitel}{Depth Estimation}
\renewcommand{\englischertitel}{Tiefenerkennung}
\makroabschnitt
\label{AbschnittStereoVisionTiefenerkennung}

Test Eng

\colger

1. Creating a disparity map and tuning it with Block Matching and Semi Global Block Matching
2. From disparity map to depth map.

\colende